# -*- coding: utf-8 -*-
"""FDNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16TkIsOTwOKck4ShwrwX7Yzj-8ddZm-KZ
"""

import pandas as pd
import tensorflow as tf
import matplotlib.pyplot as plt
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix
from tensorflow import keras
from keras.models import Sequential
from keras.layers import Dense

# Limpiar la sesión de Keras y establecer semillas aleatorias para reproducibilidad
keras.backend.clear_session()
tf.random.set_seed(42)
np.random.seed(42)

# Ruta del archivo CSV de datos y almacenamiento en df
#path = r'C:\Users\cuats\OneDrive\Escritorio\Sol. Librerias DNN\fetal_health.csv'   #VSC
path = '/content/fetal_health.csv'  # Google Colab
df = pd.read_csv(path)

# Separar características (x) y etiquetas (y)
dfx = df.loc[:, df.columns != 'fetal_health']
x = dfx
y = df['fetal_health']

# Dividir el conjunto de datos en conjuntos de entrenamiento, validación y prueba (60%, 20%, 20%)
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1, stratify=y)
x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.25, random_state=1)  # 0.25 x 0.8 = 0.2

# Número de neuronas en la primera capa = features
first_layerNeurons = x.shape[1]

# Inicialización de pesos: Se utiliza una inicialización de pesos llamada VarianceScaling que configura
# los pesos de las capas iniciales de la red neuronal de tal manera que su varianza sea escalada por un factor de 2.
# Esto puede ayudar a estabilizar el entrenamiento y acelerar la convergencia de la red.
init = keras.initializers.VarianceScaling(scale=2, mode='fan_avg', distribution='uniform')

# Optimizador: Se utiliza el optimizador Nadam (Adam con Nesterov momentum) como método para actualizar los pesos de la red durante el entrenamiento.
# El optimizador Nadam es una variante del optimizador Adam que combina las ventajas del método Nesterov Accelerated Gradient (NAG) y Adam.
nadamopt = tf.keras.optimizers.Nadam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)

# Callback de detención temprana: Se crea un callback llamado "early_stopping" que se utilizará durante el entrenamiento.
# Este callback monitorea la métrica de pérdida en el conjunto de validación y detiene el entrenamiento si la pérdida
# en el conjunto de validación no mejora después de un cierto número de épocas definido por "patience".
# La opción "restore_best_weights=True" permite restaurar los pesos del modelo a la mejor iteración en términos de pérdida en el conjunto de validación.
early_stopping = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)

# Función para crear el modelo de red neuronal secuencial
def create_model():
    model = Sequential()
    # Capa de entrada con función de activación relu y la inicialización de pesos seleccionada
    model.add(Dense(first_layerNeurons, input_dim=21,
                    kernel_initializer=init, activation='relu'))
    # Construcción de 20 capas ocultas de 42 neuronas
    for i in range(20):
        #misma inicialización de pesos y función de activación
        model.add(Dense(42, kernel_initializer=init, activation='relu'))
    #Capa de salida de mismas dimensions que la variable objetivo. Variando esta vez
    # la función de activación por una sigmoidal
    model.add(Dense(y_train.T.shape[0], kernel_initializer=init, activation='sigmoid'))
    # Compilación del modelo con optimizador Nadam
    # Como función de pérdida se opta por "      ", pues nuestra variable objetivo es multiclase
    model.compile(optimizer=nadamopt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])
    return model

# Crear el modelo
model1 = create_model()

# Entrenar el modelo, seleccionamos 1000 épcoas pues sabemos que el callback no las dejará correr todas
history1 = model1.fit(x_train, y_train, epochs=1000, validation_data=(x_val, y_val), callbacks=[early_stopping])

# Evaluar el modelo en el conjunto de prueba
score1 = model1.evaluate(x_test, y_test)
print('Pérdida en el conjunto de prueba:', score1[0])
print('Exactitud en el conjunto de prueba:', score1[1])

# Visualización de las curvas de pérdida y exactitud durante el entrenamiento
plt.figure(figsize=(12, 6))
plt.subplot(1, 2, 1)
plt.plot(history1.history['loss'], label='Entrenamiento')
plt.plot(history1.history['val_loss'], label='Validación')
plt.title('Pérdida del Modelo')
plt.xlabel('Época')
plt.ylabel('Pérdida')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history1.history['accuracy'], label='Entrenamiento')
plt.plot(history1.history['val_accuracy'], label='Validación')
plt.title('Exactitud del Modelo')
plt.xlabel('Época')
plt.ylabel('Exactitud')
plt.legend()
plt.show()

# Análisis de sesgo y varianza
# Calcular sesgo (error de entrenamiento)
train_loss, train_accuracy = model1.evaluate(x_train, y_train, verbose=0)
sesgo = 1 - train_accuracy

# Calcular varianza (diferencia entre pérdida de validación y entrenamiento)
val_loss, val_accuracy = model1.evaluate(x_val, y_val, verbose=0)
varianza = val_loss - train_loss

print(f'Sesgo (Error de Entrenamiento): {sesgo:.4f}')
print(f'Varianza: {varianza:.4f}')

# Análisis del ajuste del modelo
# Determinar si el modelo está subajustado, sobreajustado o bien ajustado
if sesgo > 0.2:
    ajuste_modelo = 'Subajustado'
elif sesgo <= 0.2 and varianza > 0.2:
    ajuste_modelo = 'Sobreajustado'
else:
    ajuste_modelo = 'Bien Ajustado'

print(f'Ajuste del Modelo: {ajuste_modelo}')

# Evaluar el modelo en el conjunto de prueba nuevamente
score1 = model1.evaluate(x_test, y_test)
print('Pérdida en el conjunto de prueba:', score1[0])
print('Exactitud en el conjunto de prueba:', score1[1])

# Predecir las clases en el conjunto de prueba
y_pred = model1.predict(x_test)
y_pred_classes = np.argmax(y_pred, axis=1)

# Puntuación de recuperación (Recall) y Puntuación F1
from sklearn.metrics import recall_score, f1_score

recall = recall_score(y_test, y_pred_classes, average='weighted')
f1 = f1_score(y_test, y_pred_classes, average='weighted')

print(f"Puntuación de Recuperación: {recall:.4f}")
print(f"Puntuación F1: {f1:.4f}")

# Matriz de confusión
confusion_mtx = confusion_matrix(y_test, y_pred_classes)
print("Matriz de Confusión:")
print(confusion_mtx)